{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUx7hqXkyz_7"
   },
   "source": [
    "# Computing sentence embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6J3UbpQ3yz_9"
   },
   "source": [
    "A first prototype on a small corpus, following https://openreview.net/pdf?id=SyK00v5xx.\n",
    "\n",
    "The basic idea is to compute the sentence vector v_s as a weighted average of the word vectors associated with the words contained in s. The weight of each vector is an inverse function of the probability of the corresponding word in the corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46XmyxsWyz__"
   },
   "source": [
    "![s_formula](img/algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the following ingredients:\n",
    "\n",
    "1) a set of sentences (corpus)\n",
    "\n",
    "2) the vocabulary of corpus (unique tokens)\n",
    "\n",
    "3) the probability of each word in the vocabulary (frequency in the corpus)\n",
    "\n",
    "4) a word vector (embedding) for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tIOMN4Xy0AA"
   },
   "source": [
    "Import basic packages first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obSL0qBiy0AB"
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import re # regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTq79VMqy0AF"
   },
   "source": [
    "The parameter a is manually set to 0.001 (see paper):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSzEmX2oy0AH"
   },
   "outputs": [],
   "source": [
    "a = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-_Ed7Czy0AM"
   },
   "source": [
    "Next, we load our corpus, which is a random sample of 50k sentences from OpenSubtitles corpus available at http://opus.nlpl.eu/OpenSubtitles-v2018.php. The full corpus has been slightly cleaned and the sample obtained with bash command shuf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jner1MkMy0AN"
   },
   "outputs": [],
   "source": [
    "with open('data/mini-subtitles-corpus', 'r') as input_file:\n",
    "    corpus = input_file.read()\n",
    "\n",
    "corpus = re.sub('\\n', '. ', corpus) # we'll split sentences based on full stops with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "6dG8TtH1y0AR",
    "outputId": "5fc22907-7cea-4108-b374-5d356d2a9c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"ok, beh, apprezzo la tua preoccupazione. avresti dovuto dirle prima queste cose. ti stai divertendo, blaine. sono miei ormai. quando ero a princeton, ho scritto la mia tesi sulle passioni degli stoici. hai una macchia sul tuo file, delinquente. presto anche tu capirai. se non lo fai, lo chiamo e gli dico dove sei. beh, sarebbe stato prima che venissi uccisa, ma funziona anche così. usa la presa al ginocchio. dolore e dai desideri. di che puntualizzazione parli. nella mia fantasia, noi ci trasferiamo nell'attico di jennifer lawrence. mazzola. perché loro non si lavano. non se ne adrà via. ah, 50ooo lire, don pietro. bob e malcolm sono stati licenziati. seq druven begnan si. molti amici mi hanno chiesto di farti ripensare a questa cosa. avrei dovuto lasciarla morire per evitare che lei odiasse me. erano un bersaglio facile mentre stavano dormendo nei loro nidi, di giorno. qual è stato il primo film western a vincere l'oscar come miglior film. magari mi fai vedere l'insegnante di inglese.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(corpus))\n",
    "corpus[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39QOzP81y0AY"
   },
   "source": [
    "A bunch of sentences, as expected.\n",
    "\n",
    "Next, we parse the corpus with spacy (it'll take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcFGYJhmy0AZ"
   },
   "outputs": [],
   "source": [
    "# import spaCy for nlp and italian resources (install if necessary)\n",
    "\n",
    "#!pip3 install spacy\n",
    "#!python3 -m spacy download it\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qfaUjedy0Ae"
   },
   "outputs": [],
   "source": [
    "nlp.max_length = 2500000\n",
    "doc = nlp(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7OlTqddy0Aj"
   },
   "outputs": [],
   "source": [
    "sentences = [sentence for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u398OJc1y0Ap"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ok, beh, apprezzo la tua preoccupazione.,\n",
       " avresti dovuto dirle prima queste cose.,\n",
       " ti stai divertendo, blaine.,\n",
       " sono miei ormai.,\n",
       " quando ero a princeton, ho scritto la mia tesi sulle passioni degli stoici.,\n",
       " hai una macchia sul tuo file, delinquente.,\n",
       " presto anche tu capirai.,\n",
       " se non lo fai, lo chiamo e gli dico dove sei.,\n",
       " beh, sarebbe stato prima che venissi uccisa, ma funziona anche così.]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gf8vVhd3y0Ay"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49669"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67cAfjo4y0A7"
   },
   "source": [
    "Get tokens, stripping punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOA6yS2ly0A8"
   },
   "outputs": [],
   "source": [
    "tokens = [token.text for token in doc if token.is_punct != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wo8SDblgy0BB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WLqYEkcy0BO"
   },
   "source": [
    "Get frequency of each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-BEcvfVy0BP"
   },
   "outputs": [],
   "source": [
    "# we use Counter from collections package\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5Lksm7Dy0BS"
   },
   "outputs": [],
   "source": [
    "tokens_count = Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2E6ZwF9Dy0BZ"
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rponPUpzy0Bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('di', 9946),\n",
       " ('che', 9785),\n",
       " ('non', 8535),\n",
       " ('è', 8055),\n",
       " ('e', 6578),\n",
       " ('la', 6408),\n",
       " ('il', 6134),\n",
       " ('un', 5647),\n",
       " ('a', 5643),\n",
       " ('per', 4860)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqVNbOdTy0Bj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_count['cane']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtCFVK31y0Bo"
   },
   "source": [
    "Get list of unique tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiY-X-7Sy0Bq"
   },
   "outputs": [],
   "source": [
    "unique_tokens = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziM86WrFy0B7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34870\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(unique_tokens)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rqob79AHy0CD"
   },
   "source": [
    "With this list we can put together a dictionary of unique tokens with their probability in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hh31H3nuy0CF"
   },
   "outputs": [],
   "source": [
    "# iterating on the keys of tokens_count object, we divide the count of each token by the length of the vocabulary\n",
    "tokens_prob = {key : tokens_count[key]/vocab_size for key in tokens_count.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHOdNniJy0CJ"
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KG8bfPUry0CK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17591052480642386"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_prob['il']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFZ-f74iy0CO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012331517063378262"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_prob['cane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-D_xd8MEy0CV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8677946659019214e-05"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_prob['segugio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tf8Vpm1Ey0Cr"
   },
   "source": [
    "Next, we train Word2Vec model on our corpus with gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kpI1RRQy0Cs"
   },
   "outputs": [],
   "source": [
    "# gensim is used to load word embeddings (install if necessary)\n",
    "\n",
    "#!pip3 install gensim\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyJuPzyqy0Cv"
   },
   "source": [
    "We need tokenized sentences as input for Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvKCrsVTy0C1"
   },
   "outputs": [],
   "source": [
    "# double list comprehension: collect tokens, stripping punctuation, for each sentence in doc\n",
    "tokenized_sentences = [[token.text for token in sentence if token.is_punct != True] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWBROawzy0C4"
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcWVwdDCy0C6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ok', 'beh', 'apprezzo', 'la', 'tua', 'preoccupazione'],\n",
       " ['avresti', 'dovuto', 'dirle', 'prima', 'queste', 'cose'],\n",
       " ['ti', 'stai', 'divertendo', 'blaine'],\n",
       " ['sono', 'miei', 'ormai'],\n",
       " ['quando',\n",
       "  'ero',\n",
       "  'a',\n",
       "  'princeton',\n",
       "  'ho',\n",
       "  'scritto',\n",
       "  'la',\n",
       "  'mia',\n",
       "  'tesi',\n",
       "  'sulle',\n",
       "  'passioni',\n",
       "  'degli',\n",
       "  'stoici'],\n",
       " ['hai', 'una', 'macchia', 'sul', 'tuo', 'file', 'delinquente'],\n",
       " ['presto', 'anche', 'tu', 'capirai'],\n",
       " ['se', 'non', 'lo', 'fai', 'lo', 'chiamo', 'e', 'gli', 'dico', 'dove', 'sei'],\n",
       " ['beh',\n",
       "  'sarebbe',\n",
       "  'stato',\n",
       "  'prima',\n",
       "  'che',\n",
       "  'venissi',\n",
       "  'uccisa',\n",
       "  'ma',\n",
       "  'funziona',\n",
       "  'anche',\n",
       "  'così']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hZYiFNmy0DJ"
   },
   "outputs": [],
   "source": [
    "vec_size = int(vocab_size ** 0.25) # rule of thumb to decide size of embedding vectors\n",
    "model = Word2Vec(tokenized_sentences,size=vec_size, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78hYuqBny0DN"
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Geg9bA3Xy0DO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04793363,  0.14515889, -0.5201173 , -0.41402858,  0.2684565 ,\n",
       "       -0.255092  ,  0.3482258 , -0.810052  ,  0.33293155], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['cane'][0:9] # show only the first nine values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtLFe5gey0Dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05598346,  0.21135338, -0.28277728, -0.20828103,  0.20839186,\n",
       "       -0.15002275,  0.1731048 , -0.3455772 ,  0.20046158], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['lupo'][0:9] # show only the first nine values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "krEiN5e-y0Du"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06719015,  0.11652127, -0.20855701, -0.20998985,  0.14426757,\n",
       "       -0.0671446 ,  0.09711676, -0.3021662 ,  0.20518269], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['gatto'][0:9] # show only the first nine values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXtGxPFby0Dy"
   },
   "source": [
    "Double check vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fz9NtLsay0D2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_unique_tokens = set([token for token in model.wv.vocab]) # unique tokens in model vocab\n",
    "model_unique_tokens == set(unique_tokens) # exaclty the same as unique_tokens above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkXJ5MAHy0D9"
   },
   "source": [
    "Cool.\n",
    "\n",
    "We have all our ingredients: sentences, tokens, probabilities and vectors.\n",
    "\n",
    "Let's move to sentence embedding algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZoMoPUTy0D-"
   },
   "outputs": [],
   "source": [
    "def compute_s_vec(sentence, a=0.001): # make sure sentence is tokenized! \n",
    "\n",
    "    sent_vec = np.zeros(shape=vec_size) # initialize vector of zeros with the wanted shape\n",
    "\n",
    "    for token in sentence: # cycle through tokens in sentence\n",
    "        token_p = tokens_prob[token] # probability of token\n",
    "        token_vec = model.wv[token] # token vector\n",
    "        weighted_token_vec = token_vec*(a/(a+token_p)) # weighted vector of token\n",
    "        sent_vec = sent_vec + weighted_token_vec # sum\n",
    "\n",
    "    sent_vec = sent_vec*(1/len(sent_vec)) # average\n",
    "\n",
    "    return(sent_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Job1Gpp1y0EB"
   },
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FLNaAhNy0EC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00506044,  0.01638964, -0.03351006, -0.02523877,  0.01940483,\n",
       "       -0.01551588,  0.02173505, -0.04574097,  0.02202952])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il_cane_lupo = compute_s_vec(['il', 'cane', 'lupo'])\n",
    "il_cane_lupo[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkUZ8_jRy0EH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00121915,  0.01220169, -0.03068349, -0.02612948,  0.01682468,\n",
       "       -0.0117225 ,  0.0183937 , -0.04478033,  0.02304901])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il_cane_gatto = compute_s_vec(['il', 'cane', 'gatto'])\n",
    "il_cane_gatto[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_a1TTS11y0EM"
   },
   "source": [
    "Finally, create a dictionary computing vector for each sentence in corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UGPAfSPLy0EN"
   },
   "outputs": [],
   "source": [
    "sentences_vector = {sentences[i] : compute_s_vec(tokenized_sentences[i]) for i in range(len(sentences))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: steps 4-7 of the algorithm above."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "computing_sentence_embeddings.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
